---
title: "Hypothesis testing"
subtitle: "<br><br> Data Science & Statistics"
author: "Gavin McNicol"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    self_contained: true
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(DT)
library(emo)
library(openintro)
library(gghighlight)
library(patchwork)
library(lubridate)
library(ggtext)
library(knitr)
library(kableExtra)
library(scales)
set.seed(1234)
options(dplyr.print_min = 10, dplyr.print_max = 6)
theme_bw <- theme_bw() + 
  theme(axis.text=element_text(size=20),
        axis.title = element_text(size = 20),
        legend.text = element_text(size = 15), 
        legend.title = element_text(size = 20),
        title = element_text(size = 15))
```

class: middle

# Hypothesis testing to compare two proportions

Due to time constraints we can only cover this subsection of hypothesis testing, however, you can still explore applying a hypothesis test to your final project data set if you can find a way to identify two proportions to compare.

---

# Recap and motivation

---

## Packages

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
```

## Data: Morgan-Monroe State Forest Tower Ecosystem Exchange

```{r out.width="40%", echo=FALSE}
knitr::include_graphics("img/monroe-tower.jpeg")
```

---

## Data

### A combination of hourly ecosystem fluxes AND meteorology data

```{r message=FALSE}
monroe_fluxes <- read_csv("data/us-mms-simple.csv") 
```

```{r fix-dates, echo = F}
monroe_fluxes <- monroe_fluxes %>% 
  mutate(date = mdy_hm(date))
head(monroe_fluxes)
```

---

## Filter for 2020; create a `season` variable

```{r echo = T, message = F}
monroe_fluxes <- monroe_fluxes %>% 
  filter(date >= "2020-01-01" & date <= "2021-01-01") %>% 
      mutate(season = ifelse(date < "2020-04-01", "winter", NA),
         season = ifelse(date < "2020-07-01" & date > "2020-04-01", "spring", season),
         season = ifelse(date < "2020-10-01" & date > "2020-07-01", "summer", season),
         season = ifelse(date < "2020-12-31" & date > "2020-10-01", "fall", season))
```

---

## Amount of precipitation

Question: Is it wetter in spring or fall?

--

.pull-left[
```{r echo = F, message = F, out.width="90%", warning = F}
monroe_fluxes %>% 
  ggplot(aes(x = date, y = precipitation, color = season)) +
  geom_segment(aes(x = date, y = 0, xend = date, yend = precipitation)) +
  scale_color_viridis_d() +
  theme_minimal() +
  labs(title = "2020 Precpitation",
       subtitle = "by season",
       y = "Precipitation (mm per hour)",
       x = "Season") +
  theme_bw +
  theme(axis.text.x = element_blank())
```
]

.pull.right[
```{r echo = F}
monroe_fluxes %>% 
  filter(season %in% c("spring", "fall")) %>% 
  group_by(season) %>% 
  summarize(total_precip = sum(precipitation, na.rm = T))
```
]

--

**Looks like similar amount of precipitation in both seasons.**

---

## Amount of precipitation - CODE

```{r echo = T, out.width="0%", message = F, warning = F}
monroe_fluxes %>% 
  ggplot(aes(x = date, y = precipitation, color = season)) +
  geom_segment(aes(x = date, y = 0, xend = date, yend = precipitation)) +
  scale_color_viridis_d() +
  theme_minimal() +
  labs(title = "2020 Precpitation",
       subtitle = "by season",
       y = "Precipitation (mm per hour)",
       x = "Season") +
  theme_bw +
  theme(axis.text.x = element_blank())
```

---

## Probability of precipiation

What if we changed our question:

**Is it more likely to rain in spring or fall?**

--

We can use a **randomization experiment** and **hypothesis test for two proportions**.

---

## Visualize probability of precipiation

Question: Is it more likely to rain in spring or fall?

```{r echo = F}
monroe_precip <- monroe_fluxes %>% 
  filter(season %in% c("spring", "fall")) %>% 
  select(date, precipitation, season) %>% 
  remove_missing() %>%
  mutate(weather = ifelse(precipitation > 0, "precip", "dry"))#<<
```

.pull-left[
```{r echo = F, out.width="90%"}
monroe_precip %>% 
  ggplot(aes(season, fill = weather)) +
  geom_bar() +
  scale_fill_manual(values = c("orange", "light green")) +
  theme_minimal() +
  labs(title = "Hours of Precipitation",
       subtitle = "In spring and Fall",
       y = "Count",
       x = "Season",
       fill = "Weather") +
  theme_bw
```
]
--

.pull.right[
Is there a difference between seasons? 

It's hard to see!
]

---

## Table of occurrences

```{r}
monroe_precip %>%
  group_by(season) %>% 
  summarize(precip = sum(weather == "precip"),
            dry = sum(weather == "dry"), 
            total_hours = n()) 
```

--

237 wet hours in fall, our of 2184 hours  
193 wet hours in spring, out of 2183 hours

---

## Parameter vs. statistic

A **parameter** for a hypothesis test is the "true" value of interest.  
We estimate the parameter using a **sample statistic** as a **point estimate**.

--

$p~$: the true difference in probability of rain in Fall vs. Spring

--

$\hat{p}~$: difference observed in the **sample**  = $\frac{precip\_yes}{total\_hours}$ (Fall) - $\frac{precip\_yes}{total\_hours}$ (Spring)

---

## Table of occurrences

```{r}
monroe_precip %>%
  group_by(season) %>% 
  summarize(precip = sum(weather == "precip"), #<<
            dry = sum(weather == "dry"), #<<
            total_hours = n()) #<<
```

---

## Parameter vs. statistic

A **parameter** for a hypothesis test is the "true" value of interest.  
We estimate the parameter using a **sample statistic** as a **point estimate**.

--

$p~$: the true difference in probability of rain in Fall vs. Spring

--

$\hat{p}~$: difference observed in the **sample**  = Fall $\frac{precip\_yes}{total\_hours}$ - Spring $\frac{precip\_yes}{total\_hours}$

$\frac{237}{2184} - \frac{193}{2183}$ =

$0.11 - 0.09 = 0.02$ 

--

From our data, rain is 2% more likely/probable in Fall than in Spring (of 2020).

**This is the a point estimate $\hat{p}~$ of the true difference $p~$**

---

## What exactly are we asking when we compare proportions in a hypothesis test?

--

We can ask: is the observed difference $\hat{p} = 0.02$ due to chance alone?

---

## Two claims

- **Null hypothesis:** "There is nothing going on, only random chance"

The variables `season` and `weather` (dry or precip) are independent. They have no relationship, and the observed difference in `weather` of 2%, was due to the natural variability inherent in the weather.

--

- **Alternative hypothesis:** "There is something going on, not random chance"

The variables `season` and `weather` (dry or precip) are **not** independent. The difference in` weather` of 2% was not due to natural variability, and fall is really more wet than spring.

---

## Hypothesis test via randomization

Steps "under the hood" for an *empirical method*:

1. Quantify our observed sample statistic $\hat{p}~  = 0.11 - 0.09 = 0.02$

--
2. Define our null and alternative hypotheses (random vs. effect of season)  

--
3. Simulate the null hypothesis using **randomization**

--
4. Calculate the randomized sample statistic again (Fall $p$ - Spring $p$)  

--
5. Do this many many times! (~1000)  

--
6. Quantify the p-value: fraction of times when randomized sample stat > sample stat  

--
7. Decide on a confidence (alpha) level, and reject $H_{0}$ if p-value < alpha  


---

## Simulating the null distribution of the sample statistic


```{r echo=TRUE, message=FALSE, warning=FALSE}
# set seed
set.seed(35)
monroe_precip %>%
  specify(weather ~ season, success = "precip") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 5, type = "permute") %>%
  calculate(stat = "diff in props", order = c("fall", "spring"))
```

---


## 1000 simulations of the null hypothesis (via randomization)

```{r echo=FALSE, message=FALSE, warning=FALSE, out.width="50%"}
# set seed
set.seed(35)
monroe_precip %>%
  specify(weather ~ season, success = "precip") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("fall", "spring")) %>%
  ggplot(aes(x = stat)) +
  geom_histogram() +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  labs(
    x = "Fall-Spring weather differences across shuffles",
    y = NULL
  ) + theme_bw
```

---

## Simulating the null distribution of the sample statistic - CODE

```{r echo=TRUE, message=FALSE, warning=FALSE, out.width="0%"}
# set seed
set.seed(35)
monroe_precip %>%
  specify(weather ~ season, success = "precip") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("fall", "spring")) %>%
  ggplot(aes(x = stat)) +
  geom_histogram() +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  labs(
    x = "Fall-Spring weather differences across shuffles",
    y = NULL
  ) + theme_bw
```


---

## Visualizing the p-value 

.question[
What is the p-value, i.e. in what % of the simulations was the simulated sample proportion at least as extreme as the observed sample proportion?
]


```{r echo=FALSE, message=FALSE, warning=FALSE, out.width="40%"}
# set seed
set.seed(35)
monroe_precip %>%
  specify(weather ~ season, success = "precip") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("fall", "spring")) %>%
  ggplot(aes(x = stat)) +
  geom_histogram() +
  gghighlight(stat >= 0.02) +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  labs(
    x = "Fall-Spring weather differences across shuffles",
    y = NULL
  ) + theme_bw
```

---

## Visualizing the p-value CODE

```{r echo=TRUE, message=FALSE, warning=FALSE, out.width="0%"}
# set seed
set.seed(35)
monroe_precip %>%
  specify(weather ~ season, success = "precip") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("fall", "spring")) %>%
  ggplot(aes(x = stat)) +
  geom_histogram() +
  gghighlight(stat >= 0.02) +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  labs(
    x = "Fall-Spring weather differences across shuffles",
    y = NULL
  ) + theme_bw
```

---

## Calculating the p-value, directly

.question[
What is the p-value, i.e. in what % of the simulations was the simulated sample proportion at least as extreme as the observed sample proportion?
]

```{r echo=TRUE}
set.seed(35)
monroe_precip %>%
  specify(weather ~ season, success = "precip") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("fall", "spring")) %>% 
  summarize(p_value = sum(stat > 0.02) / n())
```

---

## Significance level

We often use **0.05** (95% confidence) as the cutoff for whether the p-value is low enough that the data are unlikely to have come from the null model. This cutoff value is called the **significance level**, $\alpha$.

- If p-value < $\alpha$, reject $H_0$ in favor of $H_A$: The data provide convincing evidence for the alternative hypothesis.

- If p-value > $\alpha$, fail to reject $H_0$ in favor of $H_A$: The data do not provide convincing evidence for the alternative hypothesis.

---

## Conclusion

.question[
What is the conclusion of the hypothesis test?
]

--

Since the p-value of 0.014 is less than the significance level (0.05), we **reject the null hypothesis**!  
  
These tower meteorological data provide evidence that Fall was significantly **wetter** (2%) than Spring in 2020, at the Morgan Monroe State Forest.
  
However, the difference is still quite small! 


---

## Hypothesis test via randomization

Steps "under the hood" for an *empirical method*:

1. Quantify our observed sample statistic $\hat{p}~  = 0.11 - 0.09 = 0.02$

--
2. Define our null and alternative hypotheses (random vs. effect of season)  

--
3. Simulate the null hypothesis using **randomization**

--
4. Calculate the randomized sample statistic again (Fall $p$ - Spring $p$)  

--
5. Do this many many times! (~1000)  

--
6. Quantify the p-value: fraction of times when randomized sample stat > sample stat  

--
7. Decide on a confidence (alpha) level, and reject $H_{0}$ if p-value < alpha  

---

.center[
.large[
This class content was built from the Data Science in a Box source materials.
https://datasciencebox.org/index.html
]
]

